{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('py37': conda)",
   "metadata": {
    "interpreter": {
     "hash": "182d1b3cf57a9fa0e072d04044576e9d27598cb3671c31bc58ed9d1764097656"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import glob\n",
    "\n",
    "path = 'data/*.bin'\n",
    "\n",
    "files = glob.glob(path)\n",
    "\n",
    "signals = []\n",
    "\n",
    "for f in files:\n",
    "    with open(f, 'rb') as fp:\n",
    "        signal = pickle.load(fp)\n",
    "        signals.append(signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pad the 2d data to make it symmetric\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "signals_2 = []\n",
    "for signal in signals:\n",
    "    signal_2 = pad_sequences(signal, dtype='float32') \n",
    "    signals_2.append(signal_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "signals = []\n",
    "for signal in signals_2:\n",
    "    data_0 = pd.DataFrame(signal)\n",
    "    data_0.columns = data_0.columns.astype(str)\n",
    "    signals.append(data_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for signal in signals[1:]:\n",
    "    for x in range(signal.shape[1], 477):\n",
    "        signal[str(x)] = float(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 1\n",
    "for signal in signals:\n",
    "    signal['label'] = label\n",
    "    label = label + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           0         1         2         3         4         5         6  \\\n",
       "0    0.00000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1    0.00000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2    0.00000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3    0.00000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4    0.00000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "114  3.03394  2.313159  2.315145  2.218729  3.014631  2.645271  2.418086   \n",
       "115  0.00000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "116  0.00000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "117  0.00000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "118  0.00000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "            7         8         9  ...        468        469        470  \\\n",
       "0    0.000000  0.000000  0.000000  ...  60.351273  58.827641  57.969322   \n",
       "1    0.000000  0.000000  0.000000  ...   0.000000   0.000000   0.000000   \n",
       "2    0.000000  0.000000  0.000000  ...   0.000000   0.000000   0.000000   \n",
       "3    0.000000  0.000000  0.000000  ...  64.867752  62.752323  61.224167   \n",
       "4    0.000000  0.000000  0.000000  ...  28.877832  28.950697  29.149450   \n",
       "..        ...       ...       ...  ...        ...        ...        ...   \n",
       "114  2.030883  2.078114  2.141873  ...   0.000000   0.000000   0.000000   \n",
       "115  0.000000  0.000000  0.000000  ...   0.000000   0.000000   0.000000   \n",
       "116  0.000000  0.000000  0.000000  ...   0.000000   0.000000   0.000000   \n",
       "117  0.000000  0.000000  0.000000  ...   0.000000   0.000000   0.000000   \n",
       "118  0.000000  0.000000  0.000000  ...   0.000000   0.000000   0.000000   \n",
       "\n",
       "           471        472        473        474        475        476  label  \n",
       "0    58.617294  58.412926  54.821445  53.179749  51.250446  50.785027      1  \n",
       "1     0.000000   0.000000   2.224843   1.474851   0.970638   0.391956      1  \n",
       "2     0.000000   0.000000   1.382016   0.983828   1.599483   2.945693      1  \n",
       "3    60.169281  59.643188  57.596199  57.373947  57.028549  56.849007      1  \n",
       "4    30.874146  31.006813  30.445852  29.826515  28.119081  28.211523      1  \n",
       "..         ...        ...        ...        ...        ...        ...    ...  \n",
       "114   0.000000   0.000000   0.000000   0.000000   0.000000   0.000000      5  \n",
       "115   0.000000   0.000000   0.000000   0.000000   0.000000   0.000000      5  \n",
       "116   0.000000   0.000000   0.000000   0.000000   0.000000   0.000000      5  \n",
       "117   0.000000   0.000000   0.000000   0.000000   0.000000   0.000000      5  \n",
       "118   0.000000   0.000000   0.000000   0.000000   0.000000   0.000000      5  \n",
       "\n",
       "[1058 rows x 478 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>468</th>\n      <th>469</th>\n      <th>470</th>\n      <th>471</th>\n      <th>472</th>\n      <th>473</th>\n      <th>474</th>\n      <th>475</th>\n      <th>476</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>60.351273</td>\n      <td>58.827641</td>\n      <td>57.969322</td>\n      <td>58.617294</td>\n      <td>58.412926</td>\n      <td>54.821445</td>\n      <td>53.179749</td>\n      <td>51.250446</td>\n      <td>50.785027</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>2.224843</td>\n      <td>1.474851</td>\n      <td>0.970638</td>\n      <td>0.391956</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.382016</td>\n      <td>0.983828</td>\n      <td>1.599483</td>\n      <td>2.945693</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>64.867752</td>\n      <td>62.752323</td>\n      <td>61.224167</td>\n      <td>60.169281</td>\n      <td>59.643188</td>\n      <td>57.596199</td>\n      <td>57.373947</td>\n      <td>57.028549</td>\n      <td>56.849007</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>28.877832</td>\n      <td>28.950697</td>\n      <td>29.149450</td>\n      <td>30.874146</td>\n      <td>31.006813</td>\n      <td>30.445852</td>\n      <td>29.826515</td>\n      <td>28.119081</td>\n      <td>28.211523</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>114</th>\n      <td>3.03394</td>\n      <td>2.313159</td>\n      <td>2.315145</td>\n      <td>2.218729</td>\n      <td>3.014631</td>\n      <td>2.645271</td>\n      <td>2.418086</td>\n      <td>2.030883</td>\n      <td>2.078114</td>\n      <td>2.141873</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>115</th>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>116</th>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>117</th>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>118</th>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n<p>1058 rows Ã— 478 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "big_data = pd.concat(signals)\n",
    "\n",
    "big_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Step: 100  \tTraining loss (mse): 0.009098670445382595\n",
      "Step: 200  \tTraining loss (mse): 0.002118688076734543\n",
      "Step: 300  \tTraining loss (mse): 0.0007342171156778932\n",
      "Step: 400  \tTraining loss (mse): 0.00022690916375722736\n",
      "Step: 500  \tTraining loss (mse): 9.537798905512318e-05\n",
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 score: 1.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.python.framework import ops\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import tensorflow.compat.v1 as tf1\n",
    "tf1.disable_v2_behavior() \n",
    "import tensorflow as tf2 \n",
    "\n",
    "df = big_data\n",
    "\n",
    "df.label = df.label.shift(-1)\n",
    "\n",
    "# parameters\n",
    "time_steps = 1\n",
    "inputs = 477\n",
    "outputs = 5\n",
    "\n",
    "# remove nans as a result of the shifted values\n",
    "df = df.iloc[:-1,:]\n",
    "\n",
    "# convert to numoy\n",
    "df = df.values\n",
    "\n",
    "# X_y_split\n",
    "train_X = df[:, 1:]\n",
    "train_y = df[:, 0]\n",
    "\n",
    "# center and scale\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))    \n",
    "train_X = scaler.fit_transform(train_X)\n",
    "\n",
    "# reshape input to 3D array\n",
    "train_X = train_X[:,None,:]\n",
    "\n",
    "onehot_encoder = OneHotEncoder()\n",
    "encode_categorical = train_y.reshape(len(train_y), 1)\n",
    "train_y = onehot_encoder.fit_transform(encode_categorical).toarray()\n",
    "\n",
    "learning_rate = 0.001\n",
    "epochs = 500\n",
    "batch_size = int(train_X.shape[0]/2)\n",
    "length = train_X.shape[0]\n",
    "display = 100\n",
    "neurons = 100\n",
    "\n",
    "# clear graph (if any) before running\n",
    "ops.reset_default_graph()\n",
    "\n",
    "X = tf2.compat.v1.placeholder(tf2.float32, [None, time_steps, inputs])\n",
    "y = tf2.compat.v1.placeholder(tf2.float32, [None, outputs])\n",
    "\n",
    "# LSTM Cell\n",
    "cell = tf2.compat.v1.nn.rnn_cell.BasicLSTMCell(num_units=neurons, activation=tf2.compat.v1.nn.relu)\n",
    "cell_outputs, states = tf2.compat.v1.nn.dynamic_rnn(cell, X, dtype=tf2.compat.v1.float32)\n",
    "\n",
    "# pass into Dense layer\n",
    "stacked_outputs = tf2.reshape(cell_outputs, [-1, neurons])\n",
    "out = tf2.compat.v1.layers.dense(inputs=stacked_outputs, units=outputs)\n",
    "\n",
    "# squared error loss or cost function for linear regression\n",
    "loss = tf2.compat.v1.reduce_mean(tf2.compat.v1.nn.softmax_cross_entropy_with_logits_v2(\n",
    "        labels=y, logits=out))\n",
    "# optimizer to minimize cost\n",
    "optimizer = tf2.compat.v1.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "accuracy = tf2.compat.v1.metrics.accuracy(labels =  tf2.compat.v1.argmax(y, 1),\n",
    "                          predictions = tf2.compat.v1.argmax(out, 1),\n",
    "                          name = \"accuracy\")\n",
    "precision = tf2.compat.v1.metrics.precision(labels=tf2.compat.v1.argmax(y, 1),\n",
    "                                 predictions=tf2.compat.v1.argmax(out, 1),\n",
    "                                 name=\"precision\")\n",
    "recall = tf2.compat.v1.metrics.recall(labels=tf2.compat.v1.argmax(y, 1),\n",
    "                           predictions=tf2.compat.v1.argmax(out, 1),\n",
    "                           name=\"recall\")\n",
    "f1 = 2 * accuracy[1] * recall[1] / ( precision[1] + recall[1] )\n",
    "\n",
    "with tf2.compat.v1.Session() as sess:\n",
    "    # initialize all variables\n",
    "    tf2.compat.v1.global_variables_initializer().run()\n",
    "    tf2.compat.v1.local_variables_initializer().run()\n",
    "    # Train the model\n",
    "    for steps in range(epochs):\n",
    "        mini_batch = zip(range(0, length, batch_size),\n",
    "                   range(batch_size, length+1, batch_size))\n",
    "\n",
    "        # train data in mini-batches\n",
    "        for (start, end) in mini_batch:\n",
    "            sess.run(training_op, feed_dict = {X: train_X[start:end,:,:],\n",
    "                                               y: train_y[start:end,:]})\n",
    "        # print training performance \n",
    "        if (steps+1) % display == 0:\n",
    "            # evaluate loss function on training set\n",
    "            loss_fn = loss.eval(feed_dict = {X: train_X, y: train_y})\n",
    "            print('Step: {}  \\tTraining loss (mse): {}'.format((steps+1), loss_fn))\n",
    "\n",
    "    # Test model\n",
    "    acc, prec, recall, f1 = sess.run([accuracy, precision, recall, f1],\n",
    "                                     feed_dict = {X: train_X, y: train_y})\n",
    "\n",
    "    print('Accuracy:', acc[1])\n",
    "    print('Precision:', prec[1])\n",
    "    print('Recall:', recall[1])\n",
    "    print('F1 score:', f1)"
   ]
  }
 ]
}